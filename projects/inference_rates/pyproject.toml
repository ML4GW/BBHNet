[tool.pinto]
steps = [
    "multi_rate_export:export_models:resnet",
    "multi_rate_infer:launch-inference",
]

[tool.typeo.base]
basedir = "${BASE_DIR}"
datadir = "${DATA_DIR}"
accounting_group_user = "${LIGO_USERNAME}"
accounting_group = "${LIGO_GROUP}"
logdir = "${BASE_DIR}/log"
sample_rate = 2048
ifos = ['H1', 'L1']

repository_directory = "${BASE_DIR}/model_repo/"
Tb = 5184000  # 60 days of background
inference_batch_size = 128
inference_psd_length = 64
inference_sampling_rates = [1, 2, 4, 8, 16, 64]
highpass = 32
fduration = 1
kernel_length = 1.5
resnet = {layers = [3, 4, 6, 3], norm_groups = 16}

verbose = true


[tool.typeo.scripts.export-models]
logdir = "${base.logdir}"
weights = "${base.basedir}/training/weights.pt"

# input-output mapping info
repository_directory = "${base.repository_directory}"
num_ifos = 2
inference_sampling_rates = "${base.inference_sampling_rates}"
sample_rate = "${base.sample_rate}"
kernel_length = "${base.kernel_length}"
batch_size = "${base.inference_batch_size}"
fduration = "${base.fduration}"
highpass = "${base.highpass}"
psd_length = "${base.inference_psd_length}"

# repo/triton parameters
aframe_instances = 6
streams_per_gpu = 3
platform = "tensorrt_plan"
verbose = "${base.verbose}"
clean = true

# arch parameters
commands.resnet = "${base.resnet}"


[tool.typeo.scripts.launch-inference]

# paths
base_dir = "${base.basedir}"
model_repo_dir = "${base.repository_directory}"
data_dir = "${base.datadir}/test/background"
injection_set_file = "${base.datadir}/test/waveforms.h5"
log_dir = "${base.logdir}"

inference_sampling_rates = "${base.inference_sampling_rates}"

# condor args
accounting_group_user = "${base.accounting_group_user}"
accounting_group = "${base.accounting_group}"

# triton args
model_name = "aframe-stream"
model_version = -1
image = "hermes/tritonserver:22.12"
sequence_id = 1001

# timeslide args
Tb = "${base.Tb}"
shifts = [0, 1]
throughput = 6400

# data args
sample_rate = "${base.sample_rate}"
batch_size = "${base.inference_batch_size}"
ifos = "${base.ifos}"
chunk_size = 4096

# analysis args
integration_window_length = 1
cluster_window_length = 8
fduration = "${base.fduration}"
psd_length = "${base.inference_psd_length}"

# misc
verbose = "${base.verbose}"
