[tool.poetry]
name = "export"
version = "0.0.1"
description = "Export BBHNet for IaaS inference"
authors = ["Alec Gunny <alec.gunny@gmail.com>"]
# readme = "README.md"

[tool.pinto]
cuda-version = "11.2"

[tool.poetry.scripts]
export-model = "export:export"

[tool.poetry.dependencies]
python = ">=3.8,<3.11"
gwpy = "^2.1"
"hermes.typeo" = "^0.1.5"
nvidia-tensorrt = {version = "<8.2.4", source = "ngc" }
ml4gw = {path = "../../../ml4gw", develop = true}

"bbhnet.architectures" = {path = "../../../libs/architectures", extras = ["wrapper"], develop = true}
"bbhnet.base" = {path = "../../../libs/base", develop = true}
"bbhnet.data" = {path = "../../../libs/data", develop = true}
"bbhnet.logging" = {path = "../../../libs/logging", develop = true}

[tool.poetry.dependencies."hermes.quiver"]
path = "../../../hermes/hermes/hermes.quiver"
develop = true
extras = ["torch", "tensorrt"]

[tool.poetry.dev-dependencies]
pytest = "^6.2"

[[tool.poetry.source]]
# NVIDIA pypi repo for tensorrt install
name = "ngc"
url = "https://pypi.ngc.nvidia.com"

[build-system]
requires = ["poetry>=1.2"]
build-backend = "poetry.masonry.api"
